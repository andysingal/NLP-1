{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d2a25504-101b-4660-8f51-6ad5f1aaee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985ff47-f6e8-445e-b57b-a3fddbf78aed",
   "metadata": {},
   "source": [
    "# Loading Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3b82e996-3fa8-4b19-adb8-1c6ef4521c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918caeee-7826-4e7a-af96-e2881f68ed65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text Similarity Varoius Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "89d7dcc6-77cd-404c-b763-2ba6c45c8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Mapped_with_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b32e004b-514b-4e7e-b6d7-725fa1813ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>search_text</th>\n",
       "      <th>is_clicked</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_type</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>conversion_time</th>\n",
       "      <th>search_time</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000045-0de2-4ad5-9bc6-47c35b213b2f</td>\n",
       "      <td>time travel</td>\n",
       "      <td>True</td>\n",
       "      <td>aws_docs</td>\n",
       "      <td>aws_doc</td>\n",
       "      <td>SELECT</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/spark...</td>\n",
       "      <td>2022-05-18 13:09:51.000</td>\n",
       "      <td>2022-05-18 13:09:43.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000d3c6-1967-49a3-9603-490249344096</td>\n",
       "      <td>dlt.create_table</td>\n",
       "      <td>True</td>\n",
       "      <td>aws_docs</td>\n",
       "      <td>aws_doc</td>\n",
       "      <td>Delta Live Tables cookbook</td>\n",
       "      <td>https://docs.databricks.com/data-engineering/d...</td>\n",
       "      <td>2022-06-28 09:08:30.000</td>\n",
       "      <td>2022-06-28 09:08:29.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0001161c-fe72-4ba2-8cd1-70aa4e8d218f</td>\n",
       "      <td>insert overwrite ... partitions (a=x</td>\n",
       "      <td>True</td>\n",
       "      <td>aws_docs</td>\n",
       "      <td>aws_doc</td>\n",
       "      <td>INSERT OVERWRITE DIRECTORY</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/spark...</td>\n",
       "      <td>2022-03-21 19:54:03.000</td>\n",
       "      <td>2022-03-21 19:54:03.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>00015a7b-7545-4162-a8a8-fdb101426567</td>\n",
       "      <td>date minus</td>\n",
       "      <td>True</td>\n",
       "      <td>aws_docs</td>\n",
       "      <td>aws_doc</td>\n",
       "      <td>Dates and timestamps</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/dataf...</td>\n",
       "      <td>2022-06-17 09:23:33.000</td>\n",
       "      <td>2022-06-17 09:23:33.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>000182cc-4c6b-4165-8b73-4e46665942b7</td>\n",
       "      <td>live</td>\n",
       "      <td>True</td>\n",
       "      <td>aws_docs</td>\n",
       "      <td>aws_doc</td>\n",
       "      <td>Delta Live Tables cookbook</td>\n",
       "      <td>https://docs.databricks.com/data-engineering/d...</td>\n",
       "      <td>2022-06-09 15:12:54.000</td>\n",
       "      <td>2022-06-09 15:12:54.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                    id  \\\n",
       "0           0  00000045-0de2-4ad5-9bc6-47c35b213b2f   \n",
       "1           1  0000d3c6-1967-49a3-9603-490249344096   \n",
       "2           2  0001161c-fe72-4ba2-8cd1-70aa4e8d218f   \n",
       "3           4  00015a7b-7545-4162-a8a8-fdb101426567   \n",
       "4           5  000182cc-4c6b-4165-8b73-4e46665942b7   \n",
       "\n",
       "                            search_text  is_clicked index_name index_type  \\\n",
       "0                           time travel        True   aws_docs    aws_doc   \n",
       "1                      dlt.create_table        True   aws_docs    aws_doc   \n",
       "2  insert overwrite ... partitions (a=x        True   aws_docs    aws_doc   \n",
       "3                            date minus        True   aws_docs    aws_doc   \n",
       "4                                  live        True   aws_docs    aws_doc   \n",
       "\n",
       "                        title  \\\n",
       "0                      SELECT   \n",
       "1  Delta Live Tables cookbook   \n",
       "2  INSERT OVERWRITE DIRECTORY   \n",
       "3        Dates and timestamps   \n",
       "4  Delta Live Tables cookbook   \n",
       "\n",
       "                                                 url          conversion_time  \\\n",
       "0  https://docs.databricks.com/spark/latest/spark...  2022-05-18 13:09:51.000   \n",
       "1  https://docs.databricks.com/data-engineering/d...  2022-06-28 09:08:30.000   \n",
       "2  https://docs.databricks.com/spark/latest/spark...  2022-03-21 19:54:03.000   \n",
       "3  https://docs.databricks.com/spark/latest/dataf...  2022-06-17 09:23:33.000   \n",
       "4  https://docs.databricks.com/data-engineering/d...  2022-06-09 15:12:54.000   \n",
       "\n",
       "               search_time context  \n",
       "0  2022-05-18 13:09:43.000     NaN  \n",
       "1  2022-06-28 09:08:29.000     NaN  \n",
       "2  2022-03-21 19:54:03.000     NaN  \n",
       "3  2022-06-17 09:23:33.000     NaN  \n",
       "4  2022-06-09 15:12:54.000     NaN  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d03f1229-34cb-4a30-9bc5-84c7ef6d0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_search_text = df[['search_text', 'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "10f5f136-9a44-47d5-b4fa-529a69543942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time travel</td>\n",
       "      <td>SELECT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dlt.create_table</td>\n",
       "      <td>Delta Live Tables cookbook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insert overwrite ... partitions (a=x</td>\n",
       "      <td>INSERT OVERWRITE DIRECTORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date minus</td>\n",
       "      <td>Dates and timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>live</td>\n",
       "      <td>Delta Live Tables cookbook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            search_text                       title\n",
       "0                           time travel                      SELECT\n",
       "1                      dlt.create_table  Delta Live Tables cookbook\n",
       "2  insert overwrite ... partitions (a=x  INSERT OVERWRITE DIRECTORY\n",
       "3                            date minus        Dates and timestamps\n",
       "4                                  live  Delta Live Tables cookbook"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_search_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46036d-a8ed-4846-b107-9f93db23def6",
   "metadata": {},
   "source": [
    "# TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "6bff36e4-14d1-4100-af48-50957e95743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_title_search_text[\"search_text\"].tolist()\n",
    "df_train_unique= list(set(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0027b2db-1720-4002-97b6-ca5f34f9b54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27073"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2bb18-ba64-498e-a5cf-a8a38e0b3049",
   "metadata": {},
   "source": [
    "# TEST SET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d6dc9bb1-fa04-449f-b153-c26a0754d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test = pd.read_csv('databricks1-Copy1.csv')\n",
    "df_test = read_test['title'].tolist()\n",
    "df_test_unique = list(set(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ba229e37-4751-4665-a080-f4ff7555f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffdf4a-d1de-4835-8fec-efd5c182aec2",
   "metadata": {},
   "source": [
    "# Bert For Measuing Text Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "80752a27-8968-4f06-b36b-da9c735a5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "#     \"Three years later, the coffin was still full of Jello.\",\n",
    "#     \"The fish dreamed\",\n",
    "#     \"python html css fault\",\n",
    "#     \"conda activate\",\n",
    "#     \"python css\"\n",
    "# ]\n",
    "\n",
    "# test_sentences = [\n",
    "#     \"Three years later, the coffin was still full of Jello.\",\n",
    "#     \"python html\",\n",
    "#     \"The person box was packed with jelly .\",\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "80401176-f02b-47db-8030-fd65fba12364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_score = cosine_similarity([test_sentence_embedding[1]],train_sentence_embedding[0:],).flatten()\n",
    "# pd.DataFrame({\"Test_data\":test_sentences[1],\"Sentences\":sentences[0:],\"Similarity_score\":similarity_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "f3ff35e6-f9b5-4a5d-a2d1-0fdf12b68fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Embedding \n",
    "#train_embedding = model.encode(df_train_unique)\n",
    "\n",
    "\n",
    "\n",
    "def simalarity(test_set):\n",
    "    test_embedding = model.encode(df_test_unique)\n",
    "    print(len(test_embedding))\n",
    "    # append_data = []\n",
    "    # for query in range(0,len(test_embedding)):\n",
    "    #     similarity_score = cosine_similarity([test_embedding[query]],train_embedding[0:],).flatten()\n",
    "    #     data = pd.DataFrame({\"Test_set_query\":df_test_unique[query],\"Search_query\":df_train_unique,\"similarity_Score\":similarity_score })\n",
    "    #     append_data.append(data)\n",
    "    # appended_data = pd.concat(append_data)\n",
    "    # return appended_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "196f8ee9-d6fd-4d46-8d48-3207a8f3fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "cosine_data = simalarity(df_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "be5916d7-08b7-436a-8a4d-0679013d07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_data = cosine_data.sort_values(['similarity_Score'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d7271746-d22c-4b81-8b45-bb289591bebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_set_query</th>\n",
       "      <th>Search_query</th>\n",
       "      <th>similarity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11586</th>\n",
       "      <td>Could not find ADLS Gen2 Token</td>\n",
       "      <td>could not find adls gen2 token</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>SQL access</td>\n",
       "      <td>sql access</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>whitelist</td>\n",
       "      <td>whitelist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15742</th>\n",
       "      <td>Connection pool shut down</td>\n",
       "      <td>connection pool shut down</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>Cluster terminated.Reason:Self Bootstrap Failure</td>\n",
       "      <td>cluster terminated.reason:self bootstrap failure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22803</th>\n",
       "      <td>Cluster terminated.Reason:Self Bootstrap Failure</td>\n",
       "      <td>cluster terminated. reason: self bootstrap fai...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14145</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>job failure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14145</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>job failure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20624</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>cluster terminating</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>SQL access</td>\n",
       "      <td>sql-access</td>\n",
       "      <td>0.971568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>jobs failure</td>\n",
       "      <td>0.968951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>jobs failure</td>\n",
       "      <td>0.968951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>SQL access</td>\n",
       "      <td>sql data access</td>\n",
       "      <td>0.954614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7136</th>\n",
       "      <td>whitelist</td>\n",
       "      <td>whitelisted</td>\n",
       "      <td>0.944673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23921</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>cluster termination</td>\n",
       "      <td>0.941570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20652</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>cluster terminate</td>\n",
       "      <td>0.933351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>cluster terminated</td>\n",
       "      <td>0.932198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>fail job</td>\n",
       "      <td>0.916491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>fail job</td>\n",
       "      <td>0.916491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>terminated cluster</td>\n",
       "      <td>0.914323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>Cluster terminated.Reason:Self Bootstrap Failure</td>\n",
       "      <td>cluster terminated.reason:self bootstrap failu...</td>\n",
       "      <td>0.911675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24406</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>failed job</td>\n",
       "      <td>0.909655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24406</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>failed job</td>\n",
       "      <td>0.909655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>terminate cluster</td>\n",
       "      <td>0.903102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24087</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks not recognized</td>\n",
       "      <td>0.899034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>SQL access</td>\n",
       "      <td>db sql access</td>\n",
       "      <td>0.896986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7109</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks</td>\n",
       "      <td>0.896285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19166</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>failed jobs</td>\n",
       "      <td>0.895625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19166</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>failed jobs</td>\n",
       "      <td>0.895625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>Job failure</td>\n",
       "      <td>job failed</td>\n",
       "      <td>0.893879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>Job Failure</td>\n",
       "      <td>job failed</td>\n",
       "      <td>0.893879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>SQL joins gives wrong result</td>\n",
       "      <td>sql joins</td>\n",
       "      <td>0.893831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10650</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks status</td>\n",
       "      <td>0.885055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26288</th>\n",
       "      <td>SQL joins gives wrong result</td>\n",
       "      <td>joins in sql</td>\n",
       "      <td>0.882324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23200</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks utils</td>\n",
       "      <td>0.880640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>[ARR][2205190040006377 ][Procter and Gamble]th...</td>\n",
       "      <td>the spark driver has stopped unexpectedly and ...</td>\n",
       "      <td>0.878412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19508</th>\n",
       "      <td>[ARR][2205190040006377 ][Procter and Gamble]th...</td>\n",
       "      <td>the spark driver has stopped unexpectedly and ...</td>\n",
       "      <td>0.877432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15020</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks support</td>\n",
       "      <td>0.874428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks data</td>\n",
       "      <td>0.874051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25410</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>cluster created on termination</td>\n",
       "      <td>0.872047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12433</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks 11.4</td>\n",
       "      <td>0.870306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>Cluster Terminating</td>\n",
       "      <td>unexpected cluster termination</td>\n",
       "      <td>0.869826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>JDBC query connection issue</td>\n",
       "      <td>jdbc connection</td>\n",
       "      <td>0.869181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25953</th>\n",
       "      <td>SQL access</td>\n",
       "      <td>access control sql</td>\n",
       "      <td>0.868618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22345</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>/databricks-results</td>\n",
       "      <td>0.864544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10611</th>\n",
       "      <td>JDBC query connection issue</td>\n",
       "      <td>jdbc connection failure</td>\n",
       "      <td>0.863334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks.utils</td>\n",
       "      <td>0.862284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23165</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks util</td>\n",
       "      <td>0.861929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23843</th>\n",
       "      <td>Databricks Issue</td>\n",
       "      <td>databricks usage</td>\n",
       "      <td>0.859977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>SQL joins gives wrong result</td>\n",
       "      <td>sql join</td>\n",
       "      <td>0.859255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Test_set_query  \\\n",
       "11586                     Could not find ADLS Gen2 Token   \n",
       "1694                                          SQL access   \n",
       "13307                                          whitelist   \n",
       "15742                          Connection pool shut down   \n",
       "4234    Cluster terminated.Reason:Self Bootstrap Failure   \n",
       "22803   Cluster terminated.Reason:Self Bootstrap Failure   \n",
       "14145                                        Job Failure   \n",
       "14145                                        Job failure   \n",
       "20624                                Cluster Terminating   \n",
       "7557                                          SQL access   \n",
       "5930                                         Job failure   \n",
       "5930                                         Job Failure   \n",
       "10468                                         SQL access   \n",
       "7136                                           whitelist   \n",
       "23921                                Cluster Terminating   \n",
       "20652                                Cluster Terminating   \n",
       "9586                                 Cluster Terminating   \n",
       "20604                                        Job failure   \n",
       "20604                                        Job Failure   \n",
       "5795                                 Cluster Terminating   \n",
       "13067   Cluster terminated.Reason:Self Bootstrap Failure   \n",
       "24406                                        Job failure   \n",
       "24406                                        Job Failure   \n",
       "8054                                 Cluster Terminating   \n",
       "24087                                   Databricks Issue   \n",
       "19969                                         SQL access   \n",
       "7109                                    Databricks Issue   \n",
       "19166                                        Job failure   \n",
       "19166                                        Job Failure   \n",
       "10252                                        Job failure   \n",
       "10252                                        Job Failure   \n",
       "6709                        SQL joins gives wrong result   \n",
       "10650                                   Databricks Issue   \n",
       "26288                       SQL joins gives wrong result   \n",
       "23200                                   Databricks Issue   \n",
       "1558   [ARR][2205190040006377 ][Procter and Gamble]th...   \n",
       "19508  [ARR][2205190040006377 ][Procter and Gamble]th...   \n",
       "15020                                   Databricks Issue   \n",
       "157                                     Databricks Issue   \n",
       "25410                                Cluster Terminating   \n",
       "12433                                   Databricks Issue   \n",
       "21640                                Cluster Terminating   \n",
       "7235                         JDBC query connection issue   \n",
       "25953                                         SQL access   \n",
       "22345                                   Databricks Issue   \n",
       "10611                        JDBC query connection issue   \n",
       "3506                                    Databricks Issue   \n",
       "23165                                   Databricks Issue   \n",
       "23843                                   Databricks Issue   \n",
       "295                         SQL joins gives wrong result   \n",
       "\n",
       "                                            Search_query  similarity_Score  \n",
       "11586                     could not find adls gen2 token          1.000000  \n",
       "1694                                          sql access          1.000000  \n",
       "13307                                          whitelist          1.000000  \n",
       "15742                          connection pool shut down          1.000000  \n",
       "4234    cluster terminated.reason:self bootstrap failure          1.000000  \n",
       "22803  cluster terminated. reason: self bootstrap fai...          1.000000  \n",
       "14145                                        job failure          1.000000  \n",
       "14145                                        job failure          1.000000  \n",
       "20624                                cluster terminating          1.000000  \n",
       "7557                                          sql-access          0.971568  \n",
       "5930                                        jobs failure          0.968951  \n",
       "5930                                        jobs failure          0.968951  \n",
       "10468                                    sql data access          0.954614  \n",
       "7136                                         whitelisted          0.944673  \n",
       "23921                                cluster termination          0.941570  \n",
       "20652                                  cluster terminate          0.933351  \n",
       "9586                                  cluster terminated          0.932198  \n",
       "20604                                           fail job          0.916491  \n",
       "20604                                           fail job          0.916491  \n",
       "5795                                  terminated cluster          0.914323  \n",
       "13067  cluster terminated.reason:self bootstrap failu...          0.911675  \n",
       "24406                                         failed job          0.909655  \n",
       "24406                                         failed job          0.909655  \n",
       "8054                                   terminate cluster          0.903102  \n",
       "24087                          databricks not recognized          0.899034  \n",
       "19969                                      db sql access          0.896986  \n",
       "7109                                          databricks          0.896285  \n",
       "19166                                        failed jobs          0.895625  \n",
       "19166                                        failed jobs          0.895625  \n",
       "10252                                         job failed          0.893879  \n",
       "10252                                         job failed          0.893879  \n",
       "6709                                           sql joins          0.893831  \n",
       "10650                                  databricks status          0.885055  \n",
       "26288                                       joins in sql          0.882324  \n",
       "23200                                   databricks utils          0.880640  \n",
       "1558   the spark driver has stopped unexpectedly and ...          0.878412  \n",
       "19508  the spark driver has stopped unexpectedly and ...          0.877432  \n",
       "15020                                 databricks support          0.874428  \n",
       "157                                      databricks data          0.874051  \n",
       "25410                     cluster created on termination          0.872047  \n",
       "12433                                    databricks 11.4          0.870306  \n",
       "21640                     unexpected cluster termination          0.869826  \n",
       "7235                                     jdbc connection          0.869181  \n",
       "25953                                 access control sql          0.868618  \n",
       "22345                                /databricks-results          0.864544  \n",
       "10611                            jdbc connection failure          0.863334  \n",
       "3506                                    databricks.utils          0.862284  \n",
       "23165                                    databricks util          0.861929  \n",
       "23843                                   databricks usage          0.859977  \n",
       "295                                             sql join          0.859255  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "e8b8cfa7-939a-449e-9f57-c53514e9d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_groupby = cosine_data.groupby(['Test_set_query','similarity_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "cd64b89f-64dc-4550-8d84-862213a7c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_groupby = cosine_data.groupby('Test_set_query')['similarity_Score'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e64ca7f3-1e50-446b-9a2e-ae0f07eca4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_threshold_data = cosine_data.loc[(cosine_data['similarity_Score'] >= 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e4c282e8-ad70-4f91-aa83-d595184c02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby =  cosine_threshold_data.groupby(['Test_set_query','similarity_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b1ca9a3f-64ec-4373-83ec-9f46255d260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Search_query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_set_query</th>\n",
       "      <th>similarity_Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"26\" valign=\"top\">Notebook showing function does not exist</th>\n",
       "      <th>0.602650</th>\n",
       "      <td>what is a notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604145</th>\n",
       "      <td>missing function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604378</th>\n",
       "      <td>notebooktask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.606468</th>\n",
       "      <td>notebook results small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.606502</th>\n",
       "      <td>notebook hangs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.607003</th>\n",
       "      <td>notebook results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.608079</th>\n",
       "      <td>share notebook function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.608818</th>\n",
       "      <td>notebook api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.609044</th>\n",
       "      <td>featured notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.611757</th>\n",
       "      <td>get notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.613122</th>\n",
       "      <td>notebook basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.613835</th>\n",
       "      <td>notebook in notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.614452</th>\n",
       "      <td>notebook access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.621337</th>\n",
       "      <td>where is my notebook located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.622060</th>\n",
       "      <td>set notebook*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.623075</th>\n",
       "      <td>notebook isolation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.628484</th>\n",
       "      <td>call function from other notebooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.632553</th>\n",
       "      <td>notebook failed but then succeeded with re-run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.635372</th>\n",
       "      <td>notebook util</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.638597</th>\n",
       "      <td>create temporary function in notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.645931</th>\n",
       "      <td>configure notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.648152</th>\n",
       "      <td>notebook features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.656394</th>\n",
       "      <td>notebook job fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.683004</th>\n",
       "      <td>notebook functions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.700653</th>\n",
       "      <td>notebook error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.705359</th>\n",
       "      <td>notebook not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">Spark Structured Streaming Job Not Running</th>\n",
       "      <th>0.600406</th>\n",
       "      <td>spark 3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.600526</th>\n",
       "      <td>spark listener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.602425</th>\n",
       "      <td>spark cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.602722</th>\n",
       "      <td>spark code debugging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.603041</th>\n",
       "      <td>apache spark job doesn’t start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.603327</th>\n",
       "      <td>spark load dbfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604260</th>\n",
       "      <td>spark master log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604405</th>\n",
       "      <td>spark udfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604687</th>\n",
       "      <td>streaming job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.605147</th>\n",
       "      <td>spark built in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.605324</th>\n",
       "      <td>spark history server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.605881</th>\n",
       "      <td>spark.config.get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.605912</th>\n",
       "      <td>where is spark ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.607646</th>\n",
       "      <td>sparkfiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.607743</th>\n",
       "      <td>dbutils within a spark job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.608225</th>\n",
       "      <td>spark logging classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.608435</th>\n",
       "      <td>spark submit task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.610223</th>\n",
       "      <td>spark.scheduler.pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.610256</th>\n",
       "      <td>create a spark-submit job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.610914</th>\n",
       "      <td>job spark ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.612652</th>\n",
       "      <td>spark architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.613046</th>\n",
       "      <td>com.databricks.spark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.613440</th>\n",
       "      <td>spark faq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.615755</th>\n",
       "      <td>sparkdl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                Search_query\n",
       "Test_set_query                              similarity_Score                                                \n",
       " Notebook showing function does not exist   0.602650                                      what is a notebook\n",
       "                                            0.604145                                        missing function\n",
       "                                            0.604378                                            notebooktask\n",
       "                                            0.606468                                  notebook results small\n",
       "                                            0.606502                                          notebook hangs\n",
       "                                            0.607003                                        notebook results\n",
       "                                            0.608079                                 share notebook function\n",
       "                                            0.608818                                            notebook api\n",
       "                                            0.609044                                       featured notebook\n",
       "                                            0.611757                                            get notebook\n",
       "                                            0.613122                                          notebook basic\n",
       "                                            0.613835                                    notebook in notebook\n",
       "                                            0.614452                                         notebook access\n",
       "                                            0.621337                            where is my notebook located\n",
       "                                            0.622060                                           set notebook*\n",
       "                                            0.623075                                      notebook isolation\n",
       "                                            0.628484                      call function from other notebooks\n",
       "                                            0.632553          notebook failed but then succeeded with re-run\n",
       "                                            0.635372                                           notebook util\n",
       "                                            0.638597                   create temporary function in notebook\n",
       "                                            0.645931                                      configure notebook\n",
       "                                            0.648152                                       notebook features\n",
       "                                            0.656394                                       notebook job fail\n",
       "                                            0.683004                                      notebook functions\n",
       "                                            0.700653                                          notebook error\n",
       "                                            0.705359                                      notebook not found\n",
       " Spark Structured Streaming Job Not Running 0.600406                                               spark 3.0\n",
       "                                            0.600526                                          spark listener\n",
       "                                            0.602425                                             spark cache\n",
       "                                            0.602722                                    spark code debugging\n",
       "                                            0.603041                          apache spark job doesn’t start\n",
       "                                            0.603327                                         spark load dbfs\n",
       "                                            0.604260                                        spark master log\n",
       "                                            0.604405                                              spark udfs\n",
       "                                            0.604687                                           streaming job\n",
       "                                            0.605147                                          spark built in\n",
       "                                            0.605324                                    spark history server\n",
       "                                            0.605881                                        spark.config.get\n",
       "                                            0.605912                                       where is spark ui\n",
       "                                            0.607646                                              sparkfiles\n",
       "                                            0.607743                              dbutils within a spark job\n",
       "                                            0.608225                                   spark logging classes\n",
       "                                            0.608435                                       spark submit task\n",
       "                                            0.610223                                    spark.scheduler.pool\n",
       "                                            0.610256                               create a spark-submit job\n",
       "                                            0.610914                                            job spark ui\n",
       "                                            0.612652                                      spark architecture\n",
       "                                            0.613046                                    com.databricks.spark\n",
       "                                            0.613440                                               spark faq\n",
       "                                            0.615755                                                 sparkdl"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groupby.first().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f451c3ce-a377-4afc-b660-84179bb47039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3507, 3)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_threshold_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3474d4bf-59e6-4128-8608-da094f0c8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby.first().to_excel('cosine_based_on_bert.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5bcf6-5b44-49bd-ae5c-dff8080aa516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

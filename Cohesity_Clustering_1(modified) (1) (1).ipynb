{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_6LhBiwayYs"
   },
   "source": [
    "# Large scale agglomerative clustering on millions of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCJXiFX-d56E"
   },
   "source": [
    "This notebook provides the code for the article Clustering millions of sentences to optimise the ML-workflow. It shows the implementation of the scalable sentence clustering algorithm and an example of clustering 1 million Bing queries from the MS Marco dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQG3UJthcYyR"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "XNFXfqqvkYAu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sentence_transformers funcy pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "26koZKlhh1LS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NVxhuSwja7Op",
    "outputId": "b17c2d35-e9fd-4d7b-ee8b-91a851c5076a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-aebc92df-7caa-4292-99da-2fb29d4bd9de\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1657928862586145</td>\n",
       "      <td>Remove SQL server from backup | 00848226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1657924160996123</td>\n",
       "      <td>No errors SQL Database protection group not ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1657917016006422</td>\n",
       "      <td>Sensor reading critical | 00848124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1657916928916517</td>\n",
       "      <td>Helios scheduled reports not being received co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1657917583286324</td>\n",
       "      <td>CE00101009, CE00101115,CE00102203,CE00113014  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aebc92df-7caa-4292-99da-2fb29d4bd9de')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-aebc92df-7caa-4292-99da-2fb29d4bd9de button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-aebc92df-7caa-4292-99da-2fb29d4bd9de');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 id                                              query\n",
       "0  1657928862586145           Remove SQL server from backup | 00848226\n",
       "1  1657924160996123  No errors SQL Database protection group not ge...\n",
       "2  1657917016006422                 Sensor reading critical | 00848124\n",
       "3  1657916928916517  Helios scheduled reports not being received co...\n",
       "4  1657917583286324  CE00101009, CE00101115,CE00102203,CE00113014  ..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Cohesity Dataset to be worked upon.xlsx',usecols=['Session Identifier','Activity Detail'],sheet_name=\"Case Created\").rename(columns={'Session Identifier':'id','Activity Detail':'query'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFfMN2nOBdLy"
   },
   "source": [
    "# Embedding code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "uLUE0YJ6jGnI"
   },
   "outputs": [],
   "source": [
    "def embed_data(data, key='text', model_name='all-MiniLM-L6-v2', cores=1, gpu=False, batch_size=128):\n",
    "    \"\"\"\n",
    "    Embed the sentences/text using the MiniLM language model (which uses mean pooling)\n",
    "    \"\"\"\n",
    "    print('Embedding data')\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print('Model loaded')\n",
    "\n",
    "    sentences = data[key].tolist()\n",
    "    unique_sentences = data[key].unique()\n",
    "    print('Unique sentences', len(unique_sentences))\n",
    "\n",
    "    if cores == 1:\n",
    "        embeddings = model.encode(unique_sentences, show_progress_bar=True, batch_size=batch_size)\n",
    "    else:\n",
    "        devices = ['cpu'] * cores\n",
    "        if gpu:\n",
    "            devices = None  # use all CUDA devices\n",
    "\n",
    "        # Start the multi-process pool on multiple devices\n",
    "        print('Multi-process pool starting')\n",
    "        pool = model.start_multi_process_pool(devices)\n",
    "        print('Multi-process pool started')\n",
    "\n",
    "        chunk_size = math.ceil(len(unique_sentences) / cores)\n",
    "\n",
    "        # Compute the embeddings using the multi-process pool\n",
    "        embeddings = model.encode_multi_process(unique_sentences, pool, batch_size=batch_size, chunk_size=chunk_size)\n",
    "        model.stop_multi_process_pool(pool)\n",
    "\n",
    "    print(\"Embeddings computed\")\n",
    "\n",
    "    mapping = {sentence: embedding for sentence, embedding in zip(unique_sentences, embeddings)}\n",
    "    embeddings = np.array([mapping[sentence] for sentence in sentences])\n",
    "  \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvYHEi2NBQb-"
   },
   "source": [
    "# Clustering Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ilDc7zNo5-Nw"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from funcy import log_durations\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from joblib import delayed\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import pickle5 as pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def cos_sim(a: Tensor, b: Tensor):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
    "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
    "    \"\"\"\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(np.array(a))\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(np.array(b))\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "def get_embeddings(ids, embeddings):\n",
    "    return np.array([embeddings[idx] for idx in ids])\n",
    "\n",
    "\n",
    "def reorder_and_filter_cluster(\n",
    "    cluster_idx, cluster, cluster_embeddings, cluster_head_embedding, threshold\n",
    "):\n",
    "    cos_scores = cos_sim(cluster_head_embedding, cluster_embeddings)\n",
    "    sorted_vals, indices = torch.sort(cos_scores[0], descending=True)\n",
    "    bigger_than_threshold = sorted_vals > threshold\n",
    "    indices = indices[bigger_than_threshold]\n",
    "    sorted_vals = sorted_vals.numpy()\n",
    "    return cluster_idx, [(cluster[i][0], sorted_vals[i]) for i in indices]\n",
    "\n",
    "\n",
    "def get_ids(cluster):\n",
    "    return [transaction[0] for transaction in cluster]\n",
    "\n",
    "\n",
    "def reorder_and_filter_clusters(clusters, embeddings, threshold, parallel):\n",
    "    results = parallel(\n",
    "        delayed(reorder_and_filter_cluster)(\n",
    "            cluster_idx,\n",
    "            cluster,\n",
    "            get_embeddings(get_ids(cluster), embeddings),\n",
    "            get_embeddings([cluster_idx], embeddings),\n",
    "            threshold,\n",
    "        )\n",
    "        for cluster_idx, cluster in tqdm(clusters.items())\n",
    "    )\n",
    "\n",
    "    clusters = {k: v for k, v in results}\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_embeddings(ids, embeddings):\n",
    "    return np.array([embeddings[idx] for idx in ids])\n",
    "\n",
    "\n",
    "def get_clustured_ids(clusters):\n",
    "    clustered_ids = set(\n",
    "        [transaction[0] for cluster in clusters.values() for transaction in cluster]\n",
    "    )\n",
    "    clustered_ids |= set(clusters.keys())\n",
    "    return clustered_ids\n",
    "\n",
    "\n",
    "def get_clusters_ids(clusters):\n",
    "    return list(clusters.keys())\n",
    "\n",
    "\n",
    "def get_unclustured_ids(ids, clusters):\n",
    "    clustered_ids = get_clustured_ids(clusters)\n",
    "    unclustered_ids = list(set(ids) - clustered_ids)\n",
    "    return unclustered_ids\n",
    "\n",
    "\n",
    "def sort_clusters(clusters):\n",
    "    return dict(\n",
    "        sorted(clusters.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    )  # sort based on size\n",
    "\n",
    "\n",
    "def sort_cluster(cluster):\n",
    "    return list(\n",
    "        sorted(cluster, key=lambda x: x[1], reverse=True)\n",
    "    )  # sort based on similarity\n",
    "\n",
    "\n",
    "def filter_clusters(clusters, min_cluster_size):\n",
    "    return {k: v for k, v in clusters.items() if len(v) >= min_cluster_size}\n",
    "\n",
    "\n",
    "def unique(collection):\n",
    "    return list(dict.fromkeys(collection))\n",
    "\n",
    "\n",
    "def unique_txs(collection):\n",
    "    seen = set()\n",
    "    return [x for x in collection if not (x[0] in seen or seen.add(x[0]))]\n",
    "\n",
    "\n",
    "def write_pickle(data, path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def chunk(txs, chunk_size):\n",
    "    n = math.ceil(len(txs) / chunk_size)\n",
    "    k, m = divmod(len(txs), n)\n",
    "    return (txs[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(n) )\n",
    "\n",
    "\n",
    "\n",
    "def online_community_detection(\n",
    "    ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    threshold=0.7,\n",
    "    min_cluster_size=3,\n",
    "    chunk_size=2500,\n",
    "    iterations=10,\n",
    "    cores=1,\n",
    "):\n",
    "    if clusters is None:\n",
    "        clusters = {}\n",
    "\n",
    "    with Parallel(n_jobs=cores) as parallel:\n",
    "        for iteration in range(iterations):\n",
    "            print(\"1. Nearest cluster\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            cluster_ids = list(clusters.keys())\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\"Clusters\", len(cluster_ids))\n",
    "            clusters = nearest_cluster(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters,\n",
    "                chunk_size=chunk_size,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"2. Create new clusters\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            new_clusters = create_clusters(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters={},\n",
    "                min_cluster_size=3,\n",
    "                chunk_size=chunk_size,\n",
    "                threshold=threshold,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            new_cluster_ids = list(new_clusters.keys())\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"3. Merge new clusters\", len(new_cluster_ids))\n",
    "            max_clusters_size = 25000\n",
    "            while True:\n",
    "                new_cluster_ids = list(new_clusters.keys())\n",
    "                old_new_cluster_ids = new_cluster_ids\n",
    "                new_clusters = create_clusters(\n",
    "                    new_cluster_ids,\n",
    "                    embeddings,\n",
    "                    new_clusters,\n",
    "                    min_cluster_size=1,\n",
    "                    chunk_size=max_clusters_size,\n",
    "                    threshold=threshold,\n",
    "                    parallel=parallel,\n",
    "                )\n",
    "                new_clusters = filter_clusters(new_clusters, 2)\n",
    "\n",
    "                new_cluster_ids = list(new_clusters.keys())\n",
    "                print(\"New merged clusters\", len(new_cluster_ids))\n",
    "                if len(old_new_cluster_ids) < max_clusters_size:\n",
    "                    break\n",
    "\n",
    "            new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "            print(\n",
    "                f\"New clusters with min community size >= {min_cluster_size}\",\n",
    "                len(new_clusters),\n",
    "            )\n",
    "            clusters = {**new_clusters, **clusters}\n",
    "            print(\"Total clusters\", len(clusters))\n",
    "            clusters = sort_clusters(clusters)\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            print(\"4. Nearest cluster\")\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            cluster_ids = list(clusters.keys())\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\"Clusters\", len(cluster_ids))\n",
    "            clusters = nearest_cluster(\n",
    "                unclustered_ids,\n",
    "                embeddings,\n",
    "                clusters,\n",
    "                chunk_size=chunk_size,\n",
    "                parallel=parallel,\n",
    "            )\n",
    "            clusters = sort_clusters(clusters)\n",
    "\n",
    "            unclustered_ids = get_unclustured_ids(ids, clusters)\n",
    "            clustured_ids = get_clustured_ids(clusters)\n",
    "            print(\"Clustured\", len(clustured_ids))\n",
    "            print(\"Unclustured\", len(unclustered_ids))\n",
    "            print(\n",
    "                f\"Percentage clustured {len(clustured_ids) / (len(clustured_ids) + len(unclustered_ids)) * 100:.2f}%\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n\\n\")\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_ids(cluster):\n",
    "    return [transaction[0] for transaction in cluster]\n",
    "\n",
    "\n",
    "def nearest_cluster_chunk(\n",
    "    chunk_ids, chunk_embeddings, cluster_ids, cluster_embeddings, threshold\n",
    "):\n",
    "    cos_scores = cos_sim(chunk_embeddings, cluster_embeddings)\n",
    "    top_val_large, top_idx_large = cos_scores.topk(k=1, largest=True)\n",
    "    top_idx_large = top_idx_large[:, 0].tolist()\n",
    "    top_val_large = top_val_large[:, 0].tolist()\n",
    "    cluster_assignment = []\n",
    "    for i, (score, idx) in enumerate(zip(top_val_large, top_idx_large)):\n",
    "        cluster_id = cluster_ids[idx]\n",
    "        if score < threshold:\n",
    "            cluster_id = None\n",
    "        cluster_assignment.append(((chunk_ids[i], score), cluster_id))\n",
    "    return cluster_assignment\n",
    "\n",
    "\n",
    "def nearest_cluster(\n",
    "    transaction_ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    parallel=None,\n",
    "    threshold=0.75,\n",
    "    chunk_size=2500,\n",
    "):\n",
    "    cluster_ids = list(clusters.keys())\n",
    "    if len(cluster_ids) == 0:\n",
    "        return clusters\n",
    "    cluster_embeddings = get_embeddings(cluster_ids, embeddings)\n",
    "\n",
    "    c = list(chunk(transaction_ids, chunk_size))\n",
    "\n",
    "    with log_durations(logging.info, \"Parallel jobs nearest cluster\"):\n",
    "        out = parallel(\n",
    "            delayed(nearest_cluster_chunk)(\n",
    "                chunk_ids,\n",
    "                get_embeddings(chunk_ids, embeddings),\n",
    "                cluster_ids,\n",
    "                cluster_embeddings,\n",
    "                threshold,\n",
    "            )\n",
    "            for chunk_ids in tqdm(c)\n",
    "        )\n",
    "        cluster_assignment = [assignment for sublist in out for assignment in sublist]\n",
    "\n",
    "    for (transaction_id, similarity), cluster_id in cluster_assignment:\n",
    "        if cluster_id is None:\n",
    "            continue\n",
    "        clusters[cluster_id].append(\n",
    "            (transaction_id, similarity)\n",
    "        )  # TODO sort in right order\n",
    "\n",
    "    clusters = {\n",
    "        cluster_id: unique_txs(sort_cluster(cluster))\n",
    "        for cluster_id, cluster in clusters.items()\n",
    "    }  # Sort based on similarity\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def create_clusters(\n",
    "    ids,\n",
    "    embeddings,\n",
    "    clusters=None,\n",
    "    parallel=None,\n",
    "    min_cluster_size=3,\n",
    "    threshold=0.75,\n",
    "    chunk_size=2500,\n",
    "):\n",
    "    to_cluster_ids = np.array(ids)\n",
    "    np.random.shuffle(\n",
    "        to_cluster_ids\n",
    "    )  # TODO evaluate performance without, try sorted list\n",
    "\n",
    "    c = list(chunk(to_cluster_ids, chunk_size))\n",
    "\n",
    "    with log_durations(logging.info, \"Parallel jobs create clusters\"):\n",
    "        out = parallel(\n",
    "            delayed(fast_clustering)(\n",
    "                chunk_ids,\n",
    "                get_embeddings(chunk_ids, embeddings),\n",
    "                threshold,\n",
    "                min_cluster_size,\n",
    "            )\n",
    "            for chunk_ids in tqdm(c)\n",
    "        )\n",
    "\n",
    "    # Combine output\n",
    "    new_clusters = {}\n",
    "    for out_clusters in out:\n",
    "        for idx, cluster in out_clusters.items():\n",
    "            # new_clusters[idx] = unique([(idx, 1)] + new_clusters.get(idx, []) + cluster)\n",
    "            new_clusters[idx] = unique_txs(cluster + new_clusters.get(idx, []))\n",
    "\n",
    "    # Add ids from old cluster to new cluster\n",
    "    for cluster_idx, cluster in new_clusters.items():\n",
    "        community_extended = []\n",
    "        for (idx, similarity) in cluster:\n",
    "            community_extended += [(idx, similarity)] + clusters.get(idx, [])\n",
    "        new_clusters[cluster_idx] = unique_txs(community_extended)\n",
    "\n",
    "    new_clusters = reorder_and_filter_clusters(\n",
    "        new_clusters, embeddings, threshold, parallel\n",
    "    )  # filter to keep only the relevant\n",
    "    new_clusters = sort_clusters(new_clusters)\n",
    "\n",
    "    clustered_ids = set()\n",
    "    for idx, cluster_ids in new_clusters.items():\n",
    "        filtered = set(cluster_ids) - clustered_ids\n",
    "        cluster_ids = [\n",
    "            cluster_idx for cluster_idx in cluster_ids if cluster_idx in filtered\n",
    "        ]\n",
    "        new_clusters[idx] = cluster_ids\n",
    "        clustered_ids |= set(cluster_ids)\n",
    "\n",
    "    new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "    new_clusters = sort_clusters(new_clusters)\n",
    "    return new_clusters\n",
    "\n",
    "\n",
    "def fast_clustering(ids, embeddings, threshold=0.70, min_cluster_size=10):\n",
    "    \"\"\"\n",
    "    Function for Fast Clustering\n",
    "\n",
    "    Finds in the embeddings all communities, i.e. embeddings that are close (closer than threshold).\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute cosine similarity scores\n",
    "    cos_scores = cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Step 1) Create clusters where similarity is bigger than threshold\n",
    "    bigger_than_threshold = cos_scores >= threshold\n",
    "    indices = bigger_than_threshold.nonzero()\n",
    "\n",
    "    cos_scores = cos_scores.numpy()\n",
    "\n",
    "    extracted_clusters = defaultdict(lambda: [])\n",
    "    for row, col in indices.tolist():\n",
    "        extracted_clusters[ids[row]].append((ids[col], cos_scores[row, col]))\n",
    "\n",
    "    extracted_clusters = sort_clusters(extracted_clusters)  # FIXME\n",
    "\n",
    "    # Step 2) Remove overlapping clusters\n",
    "    unique_clusters = {}\n",
    "    extracted_ids = set()\n",
    "\n",
    "    for cluster_id, cluster in extracted_clusters.items():\n",
    "        add_cluster = True\n",
    "        for transaction in cluster:\n",
    "            if transaction[0] in extracted_ids:\n",
    "                add_cluster = False\n",
    "                break\n",
    "\n",
    "        if add_cluster:\n",
    "            unique_clusters[cluster_id] = cluster\n",
    "            for transaction in cluster:\n",
    "                extracted_ids.add(transaction[0])\n",
    "\n",
    "    new_clusters = {}\n",
    "    for cluster_id, cluster in unique_clusters.items():\n",
    "        community_extended = []\n",
    "        for idx in cluster:\n",
    "            community_extended.append(idx)\n",
    "        new_clusters[cluster_id] = unique_txs(community_extended)\n",
    "\n",
    "    new_clusters = filter_clusters(new_clusters, min_cluster_size)\n",
    "\n",
    "    return new_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKIx5dEzBV4u"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "PzfuGlP9iNfE"
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('./queries.train.tsv', sep='\\t', names=['id', 'query'])\n",
    "# dev = pd.read_csv('./queries.dev.tsv', sep='\\t', names=['id', 'query'])\n",
    "# eval = pd.read_csv('./queries.eval.tsv', sep='\\t', names=['id', 'query'])\n",
    "# data = pd.concat([train, dev, eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "3V-tAF7YCQYL"
   },
   "outputs": [],
   "source": [
    "ids = data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "1569a6ec0a13432e9d280e296194027c",
      "16ef4c9317c44d47bc22d8a483167916",
      "8950c5ac918442d2a3ce191678f0ccd4",
      "77e49267c4d64a1c8184ce4a93b210c6",
      "6a127b571c934a56902123b4ec9aa797",
      "ee55bb9f34744079aa2f2512604d8e33",
      "e220103f2cc3400d9b2d304ccbe71648",
      "5f0a384843f54e52bd44a43b50219f66",
      "ceb5bfca7b51499c83a01d00f6cbc1e4",
      "7d7ee6df262b4c4cb10e77cf45dfab2b",
      "0ad0c07988804d7f9677179330fe3565"
     ]
    },
    "id": "nC46kRRAuX2I",
    "outputId": "053593b7-21c4-46d0-d323-52e42fe76f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding data\n",
      "Model loaded\n",
      "Unique sentences 3717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1569a6ec0a13432e9d280e296194027c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings computed\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_data(data, 'query', cores=1)\n",
    "embeddings = {idx: embedding for idx, embedding in zip(ids, embeddings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "lceLlC2UDQyM"
   },
   "outputs": [],
   "source": [
    "clusters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLmcyJ-zBl9Y",
    "outputId": "3857a876-1e71-4e76-f618-db982e3b8209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nearest cluster\n",
      "Unclustured 3511\n",
      "Clusters 0\n",
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 25.31it/s]\n",
      "100%|██████████| 163/163 [00:00<00:00, 2582.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 189.66it/s]\n",
      "100%|██████████| 101/101 [00:00<00:00, 2747.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 101\n",
      "New clusters with min community size >= 3 101\n",
      "Total clusters 101\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2808\n",
      "Clusters 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 63.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 807\n",
      "Unclustured 2704\n",
      "Percentage clustured 22.98%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2704\n",
      "Clusters 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 66.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 21.12it/s]\n",
      "100%|██████████| 93/93 [00:00<00:00, 2405.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.24it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 2569.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 79\n",
      "New clusters with min community size >= 3 79\n",
      "Total clusters 180\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2320\n",
      "Clusters 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1225\n",
      "Unclustured 2286\n",
      "Percentage clustured 34.89%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2286\n",
      "Clusters 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 64.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 26.79it/s]\n",
      "100%|██████████| 26/26 [00:00<00:00, 1116.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 443.65it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 690.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 23\n",
      "New clusters with min community size >= 3 23\n",
      "Total clusters 203\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2206\n",
      "Clusters 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 76.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1311\n",
      "Unclustured 2200\n",
      "Percentage clustured 37.34%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2200\n",
      "Clusters 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 91.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 31.67it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 1549.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 155.62it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 1615.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 25\n",
      "New clusters with min community size >= 3 25\n",
      "Total clusters 228\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2124\n",
      "Clusters 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1389\n",
      "Unclustured 2122\n",
      "Percentage clustured 39.56%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2122\n",
      "Clusters 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 68.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.91it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1238.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 859.84it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 706.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 6\n",
      "New clusters with min community size >= 3 6\n",
      "Total clusters 234\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2104\n",
      "Clusters 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 39.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1407\n",
      "Unclustured 2104\n",
      "Percentage clustured 40.07%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2104\n",
      "Clusters 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 100.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 32.99it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1188.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 727.42it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 1450.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 9\n",
      "New clusters with min community size >= 3 9\n",
      "Total clusters 243\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2077\n",
      "Clusters 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 26.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1434\n",
      "Unclustured 2077\n",
      "Percentage clustured 40.84%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2077\n",
      "Clusters 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 48.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1109.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 843.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1360.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 3\n",
      "New clusters with min community size >= 3 3\n",
      "Total clusters 246\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2068\n",
      "Clusters 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1443\n",
      "Unclustured 2068\n",
      "Percentage clustured 41.10%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2068\n",
      "Clusters 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 41.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 34.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 744.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 764.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 593.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 1\n",
      "New clusters with min community size >= 3 1\n",
      "Total clusters 247\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2065\n",
      "Clusters 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1446\n",
      "Unclustured 2065\n",
      "Percentage clustured 41.18%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2065\n",
      "Clusters 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 61.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 29.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 648.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 813.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 780.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 1\n",
      "New clusters with min community size >= 3 1\n",
      "Total clusters 248\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2062\n",
      "Clusters 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 35.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1449\n",
      "Unclustured 2062\n",
      "Percentage clustured 41.27%\n",
      "\n",
      "\n",
      "\n",
      "1. Nearest cluster\n",
      "Unclustured 2062\n",
      "Clusters 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 70.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "2. Create new clusters\n",
      "Unclustured 2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 32.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 986.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3. Merge new clusters 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 597.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1101.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New merged clusters 2\n",
      "New clusters with min community size >= 3 2\n",
      "Total clusters 250\n",
      "\n",
      "\n",
      "\n",
      "4. Nearest cluster\n",
      "Unclustured 2056\n",
      "Clusters 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustured 1455\n",
      "Unclustured 2056\n",
      "Percentage clustured 41.44%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = online_community_detection(ids, embeddings, clusters, chunk_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eohcaf_yxacV",
    "outputId": "53f90d1f-406e-4850-cedb-3821fc28c5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database back failing Oracle backup problems | 00846672\n",
      "See Description Backup Failed Error - | 00846234\n",
      "Backup is failing for deusntymqc03-bkup.Backup-DEV.seqirus.com | 00843858\n",
      "SQL Server Backup Failure | 00843739\n",
      "Backup Configuration | 00842383\n",
      "ExchangeServer Backup is failing | 00842307\n",
      "Error with Oracle backup | 00842250\n",
      "User based backups failed with error \"Number of path exceeding 10000\" | 00842249\n",
      "Get error  during file based backup | 00839590\n",
      "Error Code 1 Unknown error VM backups failing with error code 1 | 00839417\n",
      "No error just a lengthy time interval Archive Backups are not completing | 00838109\n",
      "Sql backup failing with error  A parameter cannot be found that matches parameter name | 00837976\n",
      "Receiving this error, backups are failing | 00837511\n",
      "Database backup Issue | 00836987\n",
      "Backup of Physical server failing | 00836758\n",
      "Backup completing with warning | 00836117\n",
      "Oracle backup fails | 00835597\n",
      "Backup is failing during taking NAS backup | 00834350\n",
      "Backup Failure | 00832554\n",
      "backup failure uora9880s.bsc.bscal.com - LASCOH01 | 00830478\n",
      "Physical server backup failed | 00830270\n",
      "Database backup failure - Database is restoring | 00829072\n",
      "Oracle Db backup Failures | 00828981\n",
      "Backup succeeds but with warning message | 00828688\n",
      "Backups are failing | 00828661\n",
      "Backups are completing with warnings. | 00828522\n",
      "Final backup issue | 00827772\n",
      "failed backup message on certain mailboxes | 00827659\n",
      "42884060675 Backup run protection SQL failed | 00827245\n",
      "Failed backups | 00826371\n",
      "SQL DB backup is failing in DMaaS | 00825994\n",
      "Log Backup Error | 00822802\n",
      "Oracle DB Backups Failing | 00821876\n",
      "Backup Errors | 00821593\n",
      "Error Restore Failed | 00820284\n",
      "error when creating backups, restore not possible | 00820145\n",
      "SQL backup error | 00818973\n",
      "Oracle Database backup failing.  (Right now it seems to be logs.) | 00818608\n",
      "Assistance with install new Cohesity C4600 chasis | 00814491\n",
      "Out of Space Errors on backups | 00814482\n",
      "Error: Write of 4194304 bytes at offset 153232867328 failed Error during backup | 00813091\n",
      "All SMB Backups are failing. SMB Backup Failure | 00812988\n",
      "Oracle backups failing | 00810595\n",
      "Backup is failed with  Access is denied for a particular backup selection | 00810360\n",
      "Request for confirmation of backup error [ ref:_00D10HNRl._5001016lZJM:ref ] | 00808908\n",
      "most of file level backup jobs failed | 00804631\n",
      "Backup Failure | 00804644\n",
      "SQL backup config/error | 00804602\n",
      "Odd backup errors on pysical server | 00803186\n",
      "Backup times and error messages | 00800888\n",
      "NAS backups failing | 00797582\n",
      "Disk free space is low on the node 207027465162902 with ip 10.1.42.213. | 00796484\n",
      "SQL DB Backup Issues | 00796480\n",
      "Backup Failure and File Recovery | 00795224\n",
      "Back Up Fails | 00794983\n",
      "\n",
      "\n",
      "undefined | 00847916\n",
      "undefined | 00846491\n",
      "undefined | 00845323\n",
      "undefined | 00842679\n",
      "undefined | 00842637\n",
      "undefined | 00842226\n",
      "undefined | 00839544\n",
      "undefined | 00838263\n",
      "undefined | 00837053\n",
      "undefined | 00831632\n",
      "undefined | 00831489\n",
      "undefined | 00828847\n",
      "undefined | 00826325\n",
      "undefined | 00821931\n",
      "undefined | 00820588\n",
      "undefined | 00820278\n",
      "undefined | 00819555\n",
      "undefined | 00818875\n",
      "undefined | 00818723\n",
      "undefined | 00818537\n",
      "undefined | 00817557\n",
      "undefined | 00814323\n",
      "undefined | 00814290\n",
      "undefined | 00810567\n",
      "undefined | 00804761\n",
      "undefined | 00804566\n",
      "undefined | 00803425\n",
      "undefined | 00803287\n",
      "undefined | 00803139\n",
      "undefined | 00802223\n",
      "undefined | 00802045\n",
      "undefined | 00801153\n",
      "undefined | 00797775\n",
      "undefined | 00796336\n",
      "\n",
      "\n",
      "CE03008019 Yoda agent unhealthy | 00848023\n",
      "YodaAgentUnhealthy: Alert Code CE03008019 Yoda agent \"unhealthy\" | 00842465\n",
      "CE03008019 YodaAgentUnhealthy | 00838306\n",
      "CE03008019  Yoda agent health check failed. | 00837887\n",
      "YodaAgentUnhealthy | 00837817\n",
      "YodaAgentUnhealthy Warning | 00835661\n",
      "CE00208019 YodaAgentUnhealthy | 00832635\n",
      "CE00208019 YodaAgentUnhealthy | 00832587\n",
      "YodaAgentUnhealthy | 00831375\n",
      "93086188806 Yoda Agent Unhealthy | 00830566\n",
      "CE00208019  After Cohesity Support upgraded out 5000 series chassis we are getting a warning that the Yoda agent is unhealthy. | 00828873\n",
      "Alert Code CE03008019 Yoda agent is unhealthy. | 00828804\n",
      "CE00208019 YodaAgentUnhealthy | 00827443\n",
      "CE00208019 Alert code CE00208019 - YodaAgentUnhealthy warnings | 00826438\n",
      "CE03008019 YodaAgentUnhealthy Alerts on Cluster | 00824917\n",
      "CE03008019 Intermittent yoda unhealthy alerts | 00822898\n",
      "CE03008019 Yoda Agent Unhealthy | 00822845\n",
      "YodaAgentUnhealthy | 00818619\n",
      "Alert Code CE03008019 Yoda Unhealthy alert | 00817569\n",
      "YodaAgentUnhealthy - Alert Code CE03008019 (asx1bkagcl) | 00811860\n",
      "YodaAgentUnhealthy - Alert Code CE03008019 (asx1dragcl) | 00811855\n",
      "CE03008019 YodaAgentUnhealthy | 00811741\n",
      "YodaAgentUnhealthy  INC18967296 - bakdpnamw013601b - 169.71.77.7 - YodaAgentUnhealthy | 00809440\n",
      "Cohesity alerts : YodaAgentUnhealthy | Warning | 00809125\n",
      "CE00208019 YodaAgentUnhealthy | 00804479\n",
      "YodaAgentUnhealthy, IndexingBacklog Investigate Alert Messages | 00803371\n",
      "CE00208019 - YodaAgentUnhealthy CE00208019 - YodaAgentUnhealthy | 00803142\n",
      "CE00208019 | https://10.192.131.32/monitoring/alerts/alert/79621:1654684448954505  WATAPBKPCOH100 : WARNING | CE00208019 - YodaAgentUnhealthy | 00803143\n",
      "YodaAgentUnhealthy | 00801779\n",
      "WARNING | CE03008019 - YodaAgentUnhealthy YodaAgentUnhealthy -cckcrhonp01 | 00800757\n",
      "WARNING | CE03008019 - YodaAgentUnhealthy WARNING | CE03008019 - YodaAgentUnhealthy | 00800726\n",
      "CE03008019 YodaAgentUnhealthy CE03008019 YodaAgentUnhealthy | 00795160\n",
      "\n",
      "\n",
      "CE03601061 ClusterGatewayUnReachable | 00847824\n",
      "Cluster not reachable | 00846211\n",
      "Problem adding nodes to existing cluster | 00836863\n",
      "cluster id  7489280691805996 | 00836837\n",
      "setup cluster failed | 00835389\n",
      "Cluster Is not connecting | 00830147\n",
      "Cluster is not assigned to my Account - Helios | 00828646\n",
      "Cluster is not loading, health checks required | 00827466\n",
      "New node cannot be added to the cluster | 00827233\n",
      "CE03801007 DiskSpaceLow | 00826119\n",
      "CE03601061 ClusterGatewayUnReachable | 00826117\n",
      "nodes unrecheable Cluster DR Failure | 00823954\n",
      "Cluster not connected to Helios | 00820373\n",
      "Error patching cluster | 00818858\n",
      "One of the disk from a node in cluster is not activated | 00818486\n",
      "Cluster at 92% | 00817731\n",
      "Trouble adding nodes to cluster | 00817647\n",
      "Errors with Cluster | 00816618\n",
      "failed to add node to cluster | 00812893\n",
      "Unable to register cluster in helios | 00810563\n",
      "Node down in cluster | 00809240\n",
      "Node not seen in Add Node when attempting to expand cluster. | 00809223\n",
      "added node to cluster but capacity didnt expand | 00805940\n",
      "Add node to cluster goes wrong | 00805838\n",
      "add nodes to cluster | 00803404\n",
      "Status - Unreachable Unable to add new Nodes to cluster | 00801935\n",
      "CE03601061  ClusterGatewayUnReachable Alert | 00796558\n",
      "AddNodeFailed, Failed to add  node to the cluster | 00795082\n",
      "Unable to add cluster to AD | 00795034\n",
      "\n",
      "\n",
      "Need assistance upgrading the Cohesity cluster | 00847989\n",
      "Upgrade Cohesity Cluster from 6.5.1 to 6.6 | 00846664\n",
      "Cannot be finished to upgrade the Cohesity Cluster | 00846360\n",
      "Updating Cohesity Cluster - July 14th | 00844539\n",
      "Upgrade Cohesity on NJMTLCOHESITY1 Access Cluster Upgrade to new LTS 6.6.0d. | 00842453\n",
      "Unable to Upgrade the Cohesity Cluster from 6.5.1 to 6.6 | 00840396\n",
      "Upgrade Cluster to 6.6.0d_U4 | 00837837\n",
      "Need assistance during the cohesity cluster upgrade from 6.5.1F to 6.6.0d_u4 - coh-rebarscl-1 | 00835959\n",
      "Unable to upgrade cluster from 6.5 to 6.6 | 00835679\n",
      "coh-rebarhfa-1: Upgrade new cluster from  6.5.1f to 6.6.0d_u4 | 00831633\n",
      "Upgrade Cohesity Cluster to latest version | 00829929\n",
      "Upgrade DC2 Cohesity cluster to 6.6.0d_u4 | 00828749\n",
      "Need assistance during the cohesity cluster upgrade from 6.5.1F  to 6.6.0d_u4 | 00822699\n",
      "Need assistance during the cohesity cluster upgrade from 6.5.1F  to 6.6.0d_u4 | 00822696\n",
      "Need assistance during the cohesity cluster upgrade from 6.5.1F  to 6.6.0d_u4 | 00822663\n",
      "Upgrade Cluster to software version 6.6.0d-p17-2022May19-9b369eca | 00819051\n",
      "upgrading from Cohesity 6.5.1.f to 6.6.0d_u3 | 00813057\n",
      "Cohesity Upgrade  6.6.0d_u4 | 00812965\n",
      "Cohesity Cluster Upgrade Recommendation & Compatibility Matrix | 00811908\n",
      "Cohesity cluster upgrade | 00810565\n",
      "Upgrade DC1 Cohesity cluster to 6.6.0d_u3 patch 17 | 00810189\n",
      "[COVHESITYVE] - Cluster stuck upgrading | 00809193\n",
      "Cohesity Cluster upgrade | Cleanup cluster space command | No UPX error | 00809013\n",
      "Support for Cluster build upgrade from 6.5.1f to 6.6.0U3 | 00808593\n",
      "Need assistance to upgrade Cohesity cluster | 00802686\n",
      "Upgrade cluster to 6.6.0d_u2;Cluster name: Cohesity Environment : Test; RT in desc | 00796758\n",
      "n/a Upgrade cluster 5370315350616728  to  version 6.6.0d_u3_release-20220426_d412ffd6 | 00796686\n",
      "Cohesity Cluster upgrade to 6.6.0d-p17 | 00796538\n",
      "\n",
      "\n",
      "Cluster stuck during upgrade | 00847948\n",
      "Cluster upgrade stuck | 00845042\n",
      "Upgrade cluster to current stable version | 00845011\n",
      "Cluster Upgrade Stuck | 00839324\n",
      "Upgrade Cluster Software | 00838099\n",
      "CE00301018 Cluster Upgrade Stuck | 00838089\n",
      "question about upgrading cluster | 00837940\n",
      "Upgrade failed. Pre-upgrade validations failed. Getting error when trying to run cluster upgrade | 00835477\n",
      "Cluster Upgrade check | 00835386\n",
      "Cluster software upgrade stuck at 50% | 00832428\n",
      "Failed Cluster Upgrade | 00829976\n",
      "Unable to upgrade Cluster | 00827342\n",
      "Cluster upgrade is stalled and not successful - need help ASAP | 00821658\n",
      "The upgrade has not given any errors, but we are seeing several Alert Code CE00411001 Cluster upgrade stuck after one node updated. | 00818801\n",
      "Cluster Upgrade | 00814270\n",
      "290778432 Cluster Upgrade Stuck | 00812776\n",
      "Cluster upgrade failed to start Cluster Upgrade Failed to Start | 00810380\n",
      "Cluster down in the middle of upgrade | 00809309\n",
      "Upgrade Cluster stuck | 00808938\n",
      "Cluster Upgrade over 16hours | 00805026\n",
      "Pre Check Cluster configs for Impending Code Upgrade | 00801977\n",
      "\n",
      "\n",
      "Process yoda_exec has restarted 35 times on node 198558781884356 in last 3600 seconds. | 00843619\n",
      "CRITICAL | CE00411001 - FrequentProcessRestarts Process yoda_exec has restarted 30 times on node 966063191292 in last 86400 seconds. | 00842669\n",
      "Fatal error reported on Cluster for YODA | 00839371\n",
      "Yoda_exec has restarted 30 times on nodes in last 86400 seconds | 00838212\n",
      "process eagle_agent_exec is restarting frequently on the cluster | 00838224\n",
      "Yoda_exec restarting requently. Total storage is filling up quickly. | 00837050\n",
      "CE00411001 yoda_exec restarting frequently on cluster | 00836814\n",
      "process yoda_exec is restarting frequently on the cluster | 00833368\n",
      "[Vertafore][pure CS0030305]Yoda agent as resumed frequent restarts, see also  00770218 | 00827319\n",
      "Process yoda_exec has restarted 31 times on node 128635482405345 in last 86400 seconds | 00826248\n",
      "[cohsftest14] process yoda_exec is restarting frequently on the cluster | 00822720\n",
      "[Flashrecover][Sherwin Williams] Yoda is restarting continuously after node adds performed yesterday 'cluster is currently unavailable' | 00821575\n",
      "process yoda_exec is restarting frequently on the cluster and backup job in hung state | 00817436\n",
      "process yoda_ex*c is restarting frequently on the cluster ::  COHESITY2U1-TIMSMPGDHA | 00817430\n",
      "CE00411001 Process yoda_exec has restarted 182 times on node 268294860888944 in last 3600 seconds. | 00813010\n",
      "CE00411001  Process yoda_exec has restarted | 00812846\n",
      "CE00411001 Process yoda_exec has restarted 31 times on node 62193903047696 in last 86400 seconds. | 00805893\n",
      "COH-P01-EIT-DKDC3: CE00411001 - Process yoda_exec has restarted 32 times on node 966063297440 in last 86400 seconds. | 00803092\n",
      "Process yoda_exec has restarted 30 times on node 256096898586482 in last 86400 seconds. | 00796650\n",
      "CE00411003 - OutOfMemoryRestart Yoda_Exec restarted due to out of memory | 00795236\n",
      "Process yoda_exec is restarting frequently  Process yoda_exec is restarting frequently | 00795156\n",
      "\n",
      "\n",
      "Backup task failed with error: [kVixError]: [Code 14009] The server refused connection Backups failing with errors | 00846699\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: The provider was unable to perform the request at this time. : 0x80042306 : VSS_E_PROVIDER_VETO Cohesity Protection Job Failing | 00842523\n",
      "Backup task failed with error: [kVixError]: [Code 13] You do not have access rights to this file VM Backup failures | 00842470\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: The system was unable to flush I/O writes. : 0x80042313 : VSS_E_FLUSH_WRITES_TIMEOUT VM Backup Failure / Warning | 00838061\n",
      "Backup task failed with error: [kVSphereError]: Detected an invalid snapshot configuration. Error:An error occurred while saving the snapshot: A required file was not found. Error:An error occurred while taking a snapshot: A required file was not found. Issues with Backup | 00835499\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: The provider was unable to perform the request at this time. : 0x80042306 : VSS_E_PROVIDER_VETO Error on Physical Block Based backup | 00821742\n",
      "Backup task failed with error: [kVixError]: [Code 1] Unknown error VM Backups failing | 00821639\n",
      "Backup task failed with error: [kVixError]: [Code 1] Unknown error Problems backing up VMs on a vCenter | 00821578\n",
      "Take snapshot failed - [kAgentErrorNotRetryable]: [kVSSError]: TakeVolumeSnapshot() failed: The provider was unable to perform the request at this time. : 0x80042306 : VSS_E_PROVIDER_VETO Physical Backup Fails with Error 0x80042306 : VSS_E_PROVIDER_VETO | 00820516\n",
      "Backup task failed with error: [kVixError]: [Code 14009] The server refused connection VMWare Backup Failing | 00817625\n",
      "Backup task failed with error: [kAgentErrorNotRetryable]: [kVSSError]: TakeVolumeSnapshot() failed: DoSnapshotSet Operation cancelled because it did not complete in time | 00817582\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: VSS has reported 1 error(s) in Event Logs > Windows Logs > Application: [Volume Shadow Copy Service error: Unexpected error while calling GetStorageDependencyInformation. hr = 0x8007048f, The device is not connect Error on backup jobs | 00812859\n",
      "Backup task failed with error: [kAgentErrorNotRetryable]: [kVSSError]: TakeVolumeSnapshot() failed: The provider was unable to perform the request at this time. : 0x80042306 : VSS_E_PROVIDER_VETO | 00809102\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: The provider was unable to perform the request at this time. : 0x80042306 : VSS_E_PROVIDER_VETO Backup Task Activity for BULGPFS0001.dir.svc.accenture.com Failure | 00809097\n",
      "Backup task failed with error: [kVixError]: [Code 13] You do not have access rights to this file VM Protection Job stuck | 00805846\n",
      "Backup task failed with error: [kVixError]: [Code 14009] The server refused connection Backup task failed with error: [kVixError]: [Code 14009] The server refused connection | 00803315\n",
      "[kVSSError]: TakeVolumeSnapshot() failed: DoSnapshotSet Operation cancelled because it did not complete in time Backup Failure | 00800916\n",
      "\n",
      "\n",
      "Add additional Node to AWS cluster | 00846583\n",
      "Tech onsite cannot add nodes to existing cluster | 00844008\n",
      "Removing Node from existing Cluster | 00841630\n",
      "Unable to add the Cohesity node in the cluster. Please asap. | 00839457\n",
      "Removed node is not showing in the lobby. kindly assist | 00836811\n",
      "node removal needed to add it in to another cluster . | 00836805\n",
      "Need to Add more Cohesity nodes to the cluster | 00828849\n",
      "New nodes can't be detected when adding node | 00827784\n",
      "Issues with adding additional nodes to Cloud Cluster | 00827694\n",
      "N/A Adding nodes to cluster has stopped progressing. | 00827695\n",
      "SQL Agents not working | 00826271\n",
      "Create another cluster to add more space. | 00826269\n",
      "new node added | 00821661\n",
      "Adding nodes to Cohesity 6.5.1f cluster and getting error | 00820585\n",
      "Need assistance with new nodes addition to Cluster | 00820599\n",
      "Need to add new C5000 nodes to existing cluster | 00810600\n",
      "Unable to add nodes (7 in total) into the cluster. | 00809160\n",
      "Error adding new node | 00797921\n",
      "We require help adding new nodes to a cluster | 00795919\n",
      "\n",
      "\n",
      "CE00213027, CE00213027 System Led Amber | 00848018\n",
      "system LED is amber | 00842503\n",
      "CE00213027 Node 181140266591360 with ip 10.50.80.21 system LED: System LED Amber & CE02713004 Issue: Details: Record ID: 0x80f, Timestamp: 07/10/2022 19:13:10 UTC, Sensor ID: de, Event Data: 52a6a3, Entity_id: 7.1 Alert codes CE00213027 & CE02713004 | 00842239\n",
      "Node ID 181140264870876 with ip 10.91.121.1 system LED: System LED Amber alert on chyusnpccp01 cluster | 00838014\n",
      "coh-p03-eit-dkdc3: Found node system LED is Amber.  IP 10.72.100.228 | 00837988\n",
      "Process newscribe_exec restarted due to out of memory at chyuswpccp02 | 00835376\n",
      "Node 181140263744912 with ip 10.91.3.47 system LED: System LED Amber at cohsdcu01 cluster | 00835357\n",
      "00413027 System LED Amber alert | 00831525\n",
      "DESCRIPTION : Node ID 181140265582178 with ip 10.1.14.94 system LED: System LED Amber. CAUSE : Found node system LED is Amber. CRITICAL | CE00413027 - SystemLedAmber | 00830087\n",
      "CE00213027 System LED: System LED Amber. | 00826186\n",
      "Alert Code CE00213027 Severity Critical  Type Hardware  Category Node Status Active  Description Node 130587295132 with ip 10.10.203.14 system LED: System LED Amber.  Cause Found node system LED is Amber. Node 130587295132 with ip 10.10.203.14 system LED: System LED Amber. | 00812994\n",
      "ce00413027 LED on node .125 is amber | 00807082\n",
      "Alert Code CE00213027 Node interface issue and Amber light | 00804609\n",
      "System LED Amber | 00801957\n",
      "Node(s) w/ System LED Amber | 00800882\n",
      "CE00213027 Node 181140266590308 with ip 10.31.8.4 system LED: System LED Amber. | 00798962\n",
      "CE00213027 System LED amber | 00797841\n",
      "\n",
      "\n",
      "Helios scheduled reports not being received consistently | 00848122\n",
      "Helios Report never shows up | 00847863\n",
      "Helios Scheduled Reports | 00846398\n",
      "Cohesity Helios is not able to populate the data Helios is unable to populate the data | 00843672\n",
      "Helios  generating reports but not giving data | 00834428\n",
      "Protection Activities report on Helios send via email didn't contain any data | 00819942\n",
      "Helios report not showing information | 00819005\n",
      "Helios reports come empty | 00817741\n",
      "N/A Helios reports are not being produced correctly | 00817636\n",
      "Helios Reports not showing data for past 24 hours | 00817619\n",
      "Helios reporting not working Helios reporting appears not to be working correctly | 00817601\n",
      "Helios daily scheduled report generating with 0% backup success rate reports | 00817521\n",
      "Data not showing in Helios Reports since 18th June | 00817442\n",
      "Helios report not working properly, giving faulty information | 00813033\n",
      "Helios Reports NOT Removing Fields | 00796472\n",
      "\n",
      "\n",
      "CE03008021 ESDiskUsageExceedsThreshold | 00845121\n",
      "CRITICAL | CE03008021 ESDiskUsageExceedsThreshold | 00842356\n",
      "CE02601081 CRITICAL | CE02601081 - BMCModuleNotAvailable | 00842321\n",
      "amber light on Power Supply amber light on Power Supply - gbloncsty | 00839468\n",
      "CRITICAL | CE00411001 - FrequentProcessRestarts usroc7csty300 : CRITICAL | CE00411001 - FrequentProcessRestarts | 00839464\n",
      "CRITICAL | CE00610002 - ProtectionGroupFailed | 00835558\n",
      "CRITICAL | CE00411001 - FrequentProcessRestarts CRITICAL | CE00411001 - FrequentProcessRestarts - usmlb1csty300 : | 00822958\n",
      "CRITICAL | CE00213027 - SystemLedAmber CRITICAL | CE00213027 - SystemLedAmber - aeauh1csty | 00822855\n",
      "CE00411001 dse2bkpcs1 : CRITICAL | CE00411001 - FrequentProcessRestarts | 00818575\n",
      "24383506009 ESDiskUsageExceedsThreshold  - Critical Alerts | 00811856\n",
      "CRITICAL | CE03008021 - ESDiskUsageExceedsThreshold | 00810736\n",
      "CRITICAL | CE00411001 - FrequentProcessRestarts | 00809118\n",
      "CE00411001 and many others 11 critical issues, 13 warnings, services are down, backups are not running, no restores are  available. | 00802068\n",
      "CE00101029  CRITICAL | CE00101029 - DiskNotHealthy - usuac1csty1 -  cluster usuac1csty1 | 00801934\n",
      "CE03008021 ESDiskUsageExceedsThreshold | 00801915\n",
      "ESDiskUsageExceedsThreshold | 00796679\n",
      "\n",
      "\n",
      "CE00413005 Memory errors on node | 00842512\n",
      "ECC MEMORY ERRORS INC19349306 - bakdpcdc22502a - ECC MEMORY ERRORS | 00841435\n",
      "(INC19220555) â€“ bakdpcdc21704câ€“ 169.23.252.155 â€“ ECC MEMORY ERRORS | 00835657\n",
      "Magneto service is down INC19487052 - bakdpnamw013201d - 169.65.167.8 - Magneto service is down | 00834560\n",
      "ECC MEMORY ERRORS INC19466824 - bakdpnamw013010c - 169.22.80.44 - ECC MEMORY ERRORS | 00834531\n",
      "Memory Error Correctable ECC | 00831483\n",
      "CE02213005 Memory Error | 00830011\n",
      "Node reporting ECC memory error | 00827571\n",
      "Memory Error Correctable ECC in Node 198558786026144 with ip 10.222.61.132 | 00822759\n",
      "ECC MEMORY ERRORS INC19126333 - bakdpnamw017005a - 169.117.110.174 - ECC MEMORY ERRORS | 00818987\n",
      "ECC MEMORY ERRORS INC19016314 - bakdpcdc21706b - 169.23.252.162 - ECC MEMORY ERRORS | 00818906\n",
      "ECC MEMORY ERRORS INC18915063 - bakdpnane021405b - 169.103.222.23 - ECC MEMORY ERRORS | 00818904\n",
      "ECC MEMORY ERRORS INC18837661 - bakdpnamw014109b - 169.105.131.138 - ECC MEMORY ERRORS | 00818902\n",
      "Correctable ECC error has occurred on a DIMM | 00817429\n",
      "Memory Error Correctable Warning | 00810381\n",
      "ECC MEMORY ERRORS INC18807248 - bakdpnanw011902a - 169.79.89.236 â€“ ECC MEMORY ERRORS | 00804108\n",
      ": Memory Error Correctable ECC. Details: Record ID: 0x37f, Timestamp: 06/05/2022 08:59:13 UTC, Sensor ID: 08,  Warning event clarification and cause  Is this an issue to be concerned about. | 00800754\n",
      "[P3]: 00799844 - [cl-lon-bar01]: [CE00413006] Correctable ECC error has occurred on a DIMM | 00800627\n",
      "\n",
      "\n",
      "gateway is not reachable on node xxx | 00847600\n",
      "Node status unavailable | 00846499\n",
      "One of the node is down | 00846192\n",
      "2 nodes unreachable | 00843724\n",
      "CE00413002 Node is Down | 00838152\n",
      "Node is not reachable | 00836719\n",
      "Node unreachable-SA Node 17 | 00835694\n",
      "Backup task failed with error: [kStale]: Too many existing snapshots (411 found). Remove any stale snapshots using diskshadow or vssadmin. Snapshots  Hardware Backup | 00834449\n",
      "Metadata server on disk 12 not reachable | 00834447\n",
      "Node ID 67061594201712 with IP 192.168.10.42 is not pingable. Node didn't start | 00834427\n",
      "node is showing unreachable | 00830284\n",
      "Node Failed to add | 00829112\n",
      "Node Unreachable | 00819089\n",
      "Node ID 966063643727 with IP 172.16.111.65 is not pingable. Node not communicating | 00814383\n",
      "Node Went Down | 00811905\n",
      "Node down, unpingable | 00809156\n",
      "Node unresponsive | 00804808\n",
      "\n",
      "\n",
      "Backup job taking much longer to finish | 00843851\n",
      "Multiple backup jobs ran very slowly | 00841531\n",
      "Backup performance issue. | 00822191\n",
      "Backup Job Stuck | 00820674\n",
      "backup job running too long and affecting production when running during office hours | 00817328\n",
      "Backup Job Very slow | 00812017\n",
      "Backup jobs taking longer than expected | 00811692\n",
      "Backup jobs are running from long time | 00811503\n",
      "Slowness for AIX Backups | 00804762\n",
      "File Based Backup Slow Running | 00801806\n",
      "Cohesity backups are very slow | 00800562\n",
      "SQL backup very slow | 00797537\n",
      "Backup slow performance in DC. | 00796233\n",
      "backup of windows client is running very slow | 00796053\n",
      "All BACKUP jobs are taking FOREVER to run,  Not completing in a timely manner | 00795477\n",
      "\n",
      "\n",
      "Bridge Restart is getting hung | 00847781\n",
      "https://10.180.245.200/monitoring/alerts/alert/544213070669:1657727026954939 Protection group Test Replication Job of type kView has replication tasks with high queue wait time. | 00846716\n",
      "https://10.180.245.200/monitoring/alerts/alert/542534414978:1657629914089082 Protection group test_replication2 of type kView has replication tasks with high queue wait time. | 00846712\n",
      "https://10.180.245.200/monitoring/alerts/alert/545981155077:1657813436164459 Protection group reno-maiden-replication-daily of type kView has replication tasks with high queue wait time. | 00846703\n",
      "https://100.85.16.74/monitoring/alerts/alert/383092193172:1657806075718004 Process bridge_proxy_exec has restarted 30 times on node 150537060379296 in last 86400 seconds. | 00846700\n",
      "CE00411001 Process bridge_exec is restarting frequently | 00846506\n",
      "CE00411001 Process yoda_exec is restarting frequently | 00839605\n",
      "CE00411001 Process bridge_exec is restarting frequently - INC19577695 | 00839499\n",
      "Process bridge_exec has restarted 248 times on node 71084781790836 in last 3600 seconds. | 00839389\n",
      "FrequentProcessRestarts gandalf_server , magneto_exec, bridge_exec restarting frequently (MIT) | 00836985\n",
      "Frequent Process Restarts - bridge_exec | 00830126\n",
      "CE00411003 Process bridge_exec restarted due to out of memory | 00820659\n",
      "Alert Description: Process bridge_proxy_exec is restarting frequently Alert Description: Process bridge_proxy_exec is restarting frequently | 00820529\n",
      "DESCRIPTION : Process bridge_proxy_exec has restarted 42 times on node 67061595125880 in last 3600 seconds. CAUSE : process bridge_proxy_exec is restarting frequently on the cluster. ALERT URL : https://10.1.1.41/monitoring/alerts/alert/1827890362:1655857 error every 1 minute - Process bridge_proxy_exec has restarted XX times | 00819294\n",
      "[Sherwin-Williams] Process bridge_exec is restarting frequently | 00814555\n",
      "CE00411001 process bridge_exec is restarting frequently on node 128635482583733 | 00810270\n",
      "process bridge_exec is restarting frequently on node 114374084877784. Description Process bridge_exec has restarted 30 times on node 114374084877784 in last 86400 seconds.  Cause process bridge_exec is restarting frequently on node 114374084877784. | 00808991\n",
      "\n",
      "\n",
      "MFA for non local authentication | 00842664\n",
      "admin@local attempted to log in from \"127.0.0.1\" using Iris CLI failed with error: Authentication failed: Invalid Username or Password specified.. Audit log errors | 00839517\n",
      "Lost the ability to enter values when editting a Protection Job Run | 00839503\n",
      "Create New \"View from Template\" hangs UI | 00839466\n",
      "Cannot specify archival target if the run does not have a local copy and it is not for existing archived copy update. Lost the ability to release Legal Hold on Archive snapshots | 00839454\n",
      "MFA for new MyCohesity Accounts isn't working | 00839438\n",
      "About MFA authentication for AD users | 00838631\n",
      "MFA Reset on MyCohesity | 00831533\n",
      "n/a Help with MFA | 00829115\n",
      "Enable MFA | 00828992\n",
      "Need to login twice since 6.6.0d when using MFA? | 00826098\n",
      "MFA activation for the local admin account does not work anymore ? | 00820530\n",
      "Invalid or expired verification code. Try again Reset MFA for an account | 00820281\n",
      "New support password | 00820275\n",
      "Enable to active MFA | 00820273\n",
      "MFA does not work for user account | 00796623\n",
      "Reset MFA | 00796456\n",
      "Unable to login after enabling MFA | 00796435\n",
      "MFA not working | 00795200\n",
      "\n",
      "\n",
      "Alert Code CE00301030 Alert Code CE00301030 | 00846708\n",
      "Alert Code CE00213027 Critical error - SystemLedAmber | 00835581\n",
      "CE02806012 Alert Code CE02806012 | 00829121\n",
      "Alert Code CE03601334 Network warning | 00826081\n",
      "CE00610015 Alerts Dashboard | 00817681\n",
      "CE00413015 - PowerSupplyRemoved Alert Code CE00413015 | 00816809\n",
      "CE00610027  Need help understanding error | 00815690\n",
      "CE02701067 CE02701067 error code | 00814325\n",
      "Alert Code  CE00411003_OutOfMemoryRestart Alert Code  CE00411003_OutOfMemoryRestart | 00813705\n",
      "Alert Code  CE00401089  Alert Code  CE00401089 AppNetworkNodeUnhealthy | 00813671\n",
      "Alert Code  CE00411001  Alert Code  CE00411001 FrequentProcessRestarts | 00813664\n",
      "Alert Code  CE00411001 Alert Code  CE00411001 FrequentProcessRestarts | 00813658\n",
      "CE03801007 Alert Code  CE03801007 Details for DiskSpaceLow | 00811616\n",
      "CE01006006 Clarify an alert meaning | 00810709\n",
      "CE03008021 Alert Code  CE03008021 Details for ESDiskUsageExceedsThreshold | 00810342\n",
      "CE00411003  Alert Code  CE00411003  OutOfMemoryRestart | 00810338\n",
      "Alert Code  CE02601081  BMCModuleNotAvailable | 00803078\n",
      "CE00809022 help on various alerts | 00795078\n",
      "\n",
      "\n",
      "Client upgrade failure | 00846717\n",
      "Upgrade Client fails (Windows) | 00844995\n",
      "no error seen, just stuck Upgrade stuck at 84% | 00841424\n",
      "No error messages Software upgrade will not finish | 00830796\n",
      "UpgradeFailed Upgrade Failed - not enough disk | 00827518\n",
      "Unable to Schedule Upgrade | 00819014\n",
      "Issues with upgrade | 00817492\n",
      "Cannot perform upgrade due to disk issues. | 00811898\n",
      "Software Upgrade Fails | 00804572\n",
      "upgrade failure | 00802027\n",
      "Upgrade Error | 00800847\n",
      "upgrade failed.  Out of space.  Requesting assistance in resolving the issue. | 00799825\n",
      "upgrade stuck | 00798776\n",
      "Upgrading | 00795441\n",
      "\n",
      "\n",
      "CE03008009 IndexingBacklog CE03008009 IndexingBacklog | 00843655\n",
      "Indexing backlog | 00839372\n",
      "Backlog in indexing of VM contents. | 00838065\n",
      "CE03008009 IndexingBacklog | 00837938\n",
      "Address the following: Alert: CE00508009 IndexingBacklog | 00835739\n",
      "CE03008009 - IndexingBacklog WARNING | CE03008009 - IndexingBacklog | 00828867\n",
      "Alert: CE00508009 IndexingBacklog | 00822931\n",
      "IndexingBacklog | 00822717\n",
      "Backlog in indexing of VM contents. | 00815627\n",
      "Alert Code CE03008009 Indexing Backlog | 00807947\n",
      "Indexing Backlog | 00805826\n",
      "CE00508009 CE00508009 IndexingBacklog Error | 00801859\n",
      "indexing backlog increases permanently - please troubleshoot | 00796348\n",
      "\n",
      "\n",
      "Upgrade assistance needed from 6.6.0.B to 6.6.0.D | 00847962\n",
      "Update to Version 6.6 | 00843850\n",
      "Question on upgrade to 6.6.0x | 00836833\n",
      "Upgrade from 6.5.1f to 6.6.0d_u4 | 00831475\n",
      "Upgrade from 6.6.0d_u2 to 6.6.0d_u4 | 00828783\n",
      "Upgrade to version 6.6 | 00820626\n",
      "Upgrade to 6.6 [LTS] | 00820303\n",
      "no error Update to 6.6.0d_u4 | 00814221\n",
      "Need to upgrade to 6.6.0.d_u4 | 00811987\n",
      "n/a Upgrade to v6.6.0d Stalled | 00804657\n",
      "Upgrade to 6.6.0d_u3 Stuck | 00803469\n",
      "Upgrading from 6.5.1f_u1 to 6.6.0d_u3 | 00802167\n",
      "Upgraded said fail, but system showed 6.6, I am seeing a lot of errors | 00795306\n",
      "\n",
      "\n",
      "Restore is failing stating path not found. | 00843734\n",
      "SQLDB restore assistance | 00838362\n",
      "unable to restore sql backup | 00831099\n",
      "Need assistance with restore | 00827712\n",
      "Oracle DB restores are failing | 00826362\n",
      "Restore Failure - File | 00826368\n",
      "Restore issue | 00825932\n",
      "file restores fail | 00822873\n",
      "Email Restore Assistance | 00817648\n",
      "Unable to restore files & folder | 00817598\n",
      "Restore problems | 00809020\n",
      "Folder restore issue | 00796514\n",
      "\n",
      "\n",
      "CE03801007 DIsk free space low message | 00846517\n",
      "CE03801007  DiskSpaceLow | 00843705\n",
      "CE03801007 DiskSpaceLow â€“ Surprise, Surprise | 00842262\n",
      "DiskSpaceLow Low space warnings | 00831461\n",
      "CE00101007 AgeroSharedServicesCohesity-East : INFO | CE00101007 - DiskSpaceLow | 00825850\n",
      "DiskSpaceLow DisksSpaceLow in Health | 00822793\n",
      "DiskSpaceLow | 00819062\n",
      "DiskSpaceLow alert on Cluster | 00810533\n",
      "CE03801007 diskspace low and frequent process restart | 00810214\n",
      "CE03801007 DiskSpaceLow Alert | 00809074\n",
      "CE03801007 disk space low | 00803057\n",
      "All Clusters - Alert: CE00101007 DiskSpaceLow | 00800961\n",
      "\n",
      "\n",
      "no error upgrade to 6.0.6.d.4 stuck | 00835235\n",
      "In the \"All Clusters\" mode Helios is showing  one of the clusters (aslccohe1-clu) as critical. | 00831631\n",
      "CE02701067 After upgrading Cluster from 6.5.0 to 6.6.0d_u4 : Security policy denial found on node | 00831614\n",
      "none Upgrading 4 node Coheisty cluste to 6.6.0d_u4 seems to be stuck in a loop | 00830146\n",
      "Upgrade 6.6.0d u4 fail node loop reboot | 00827664\n",
      "Node failed during upgrade to 6.6.0d.u4 | 00817563\n",
      "2 nodes failed in upgrade new release 6.6.0.d_4 zmpcl438 znd zmpcl441 | 00817466\n",
      "Unable to upgrade Cluster to 6.6.0d_u4 due to no space left on device error | 00814416\n",
      "N/A Upgrade to 6.6.0d_u4_release-20220608_0753663c stuck on the last 2 nodes of 7 | 00814381\n",
      "Node not progressing in upgrade to 6.6.0d_u4_release-20220608_0753663c | 00811762\n",
      "upgrade to 6.6.0d u3 never completes on 2 nodes | 00804653\n",
      "Upgrade from 6.5 to 6.6 is stocked pending 2 of 7 nodes since 48 hours | 00797881\n",
      "Node lost after upgrade from 6.6.0d_u2 to 6.6.0d_u3 | 00795010\n",
      "\n",
      "\n",
      "INFO | CE00101007 - DiskSpaceLow Disk free space is low on the node 1508743112103456 | 00847878\n",
      "CE03801007 CE03801007 - Free disk space 0% on / is below the threshold 5% | 00846220\n",
      "COHKCE01 - Disk free space is low on node | 00845237\n",
      "Disk free space is low Disk free space is low on several nodes | 00842530\n",
      "IndexingBacklog warning at chyuswpccp05 cluster | 00841462\n",
      "Disk free space is low on the node 150537062698028 with ip 10.33.210.27 at chyuswpccp02 cluster | 00841454\n",
      "Node 128635482583889 is unable to connect to any domain controller in.... | 00838169\n",
      "Duplicate IP detected in 128635482491994 | 00838168\n",
      "Disk free space is low on the node  | Free disk space 0% on / is below the threshold 3% | 00838156\n",
      "Free disk space 0% on / is below the threshold 3% Free disk space 0% on / is below the threshold 3% | 00836749\n",
      "CE03801007 Disk free space is low on the node | 00835503\n",
      "CE03801007 Disk free space is low on the node 130593348196 with ip 10.91.198.12. | 00826219\n",
      "Disk free space is low on the node 181140264582440 with ip 10.135.208.50. | 00808871\n",
      "Free disk space 9% on / is below the threshold 10% We are seeing DiskSpaceLow for this cluster's all nodes | 00800844\n",
      "DESCRIPTION : Disk free space is low on the node 268294860885248 with ip 10.183.64.23. CAUSE : Free disk space 4% on / is below the threshold 5% ALERT URL : https://10.183.64.22/monitoring/alerts/alert/7255630107:1653958756433752 root file system DiskSpaceLow , Its currently at 96% full | 00794982\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cluster in list(clusters.values())[:25]:\n",
    "  print('\\n'.join(data['query'][data.id.isin([tx[0] for tx in cluster])])+'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "fIhUxD5rYwl3"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/73569335/pandas-creating-csv-file-from-for-loop\n",
    "# value_counts_list = []\n",
    "# for cluster in list(clusters.values()):\n",
    "#   value_counts_list.append(' \\n '.join(data['query'][data.id.isin([tx[0] for tx in cluster])])+' \\n\\n ')\n",
    "# pd.DataFrame(value_counts_list).to_excel(\"new_hcp1.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "oCa5Fqp_D421"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "value_counts_list = []\n",
    "cluster_list = []\n",
    "for cluster in list(clusters.values()):\n",
    "  value_counts_list.extend(data['query'][data.id.isin([tx[0] for tx in cluster])])\n",
    "\n",
    "  l = len(data['query'][data.id.isin([tx[0] for tx in cluster])])\n",
    "  \n",
    "  #print(data['query'][data.id.isin([tx[0] for tx in cluster])][:3])\n",
    "  for x in range(l):\n",
    "    cluster_list.append(count)\n",
    "  count += 1\n",
    "\n",
    "  #value_counts_list.append('\\n'.join(data['query'][data.id.isin([tx[0] for tx in cluster])])+'\\n\\n')\n",
    "  # print(value_counts_list)\n",
    "#pd.DataFrame(value_counts_list).to_excel(\"new_hcp.xlsx\")\n",
    "\n",
    "\n",
    "cluster_df = pd.DataFrame({'Cluster':cluster_list,'Query':value_counts_list})\n",
    "\n",
    "cluster_df['Case_id'] = cluster_df['Query'].apply(lambda x :  x.split('|')[1].strip() )\n",
    "cluster_df['Query'] = cluster_df['Query'].apply(lambda x :  x.split('|')[0].strip() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5vpZHRWG4Pq",
    "outputId": "7d57a3dc-7e3d-49b8-9a43-3685763b888f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "U9QzAbjRC6UE",
    "outputId": "950aa0f8-035f-44e5-f8f3-a91aad39a655"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f19a0450-cd67-4321-9b81-6eb85c5e6642\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Query</th>\n",
       "      <th>Case_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Database back failing Oracle backup problems</td>\n",
       "      <td>00846672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>See Description Backup Failed Error -</td>\n",
       "      <td>00846234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Backup is failing for deusntymqc03-bkup.Backup...</td>\n",
       "      <td>00843858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>SQL Server Backup Failure</td>\n",
       "      <td>00843739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Backup Configuration</td>\n",
       "      <td>00842383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f19a0450-cd67-4321-9b81-6eb85c5e6642')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f19a0450-cd67-4321-9b81-6eb85c5e6642 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f19a0450-cd67-4321-9b81-6eb85c5e6642');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Cluster                                              Query   Case_id\n",
       "0        0       Database back failing Oracle backup problems  00846672\n",
       "1        0              See Description Backup Failed Error -  00846234\n",
       "2        0  Backup is failing for deusntymqc03-bkup.Backup...  00843858\n",
       "3        0                          SQL Server Backup Failure  00843739\n",
       "4        0                               Backup Configuration  00842383"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "neYQljJIcqlB"
   },
   "outputs": [],
   "source": [
    "# #https://cmdlinetips.com/2020/06/pandas-explode-convert-list-like-column-elements-to-separate-rows/\n",
    "# df1 = pd.read_excel('new_hcp1.xlsx').rename(columns = {'Unnamed: 0':'Cluster',0 : 'query'}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCuOxaKeQ-za"
   },
   "outputs": [],
   "source": [
    "# df1['query'] = df1['query'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-GEpmoqp2Dl"
   },
   "outputs": [],
   "source": [
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFX3RKPmrfIL"
   },
   "outputs": [],
   "source": [
    "# df1['query'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBXgahTBKyB-"
   },
   "outputs": [],
   "source": [
    "# #https://stackoverflow.com/questions/71175458/splitting-row-into-multiple-rows-in-pandas-dataframe\n",
    "# df2 = (\n",
    "#  df1.assign(Query=df1['query'].str.split('\\n'))\n",
    "#    .explode('Query')\n",
    "#    .reset_index(drop=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0aUs4ZgLlE6"
   },
   "outputs": [],
   "source": [
    "# df2 = df2[['Cluster','Query']]\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "UwgJ04LRLmze"
   },
   "outputs": [],
   "source": [
    "cluster_df.to_csv('hcp_mod.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1gNuewkL_vz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "EQG3UJthcYyR",
    "IFfMN2nOBdLy",
    "ZvYHEi2NBQb-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ad0c07988804d7f9677179330fe3565": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1569a6ec0a13432e9d280e296194027c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_16ef4c9317c44d47bc22d8a483167916",
       "IPY_MODEL_8950c5ac918442d2a3ce191678f0ccd4",
       "IPY_MODEL_77e49267c4d64a1c8184ce4a93b210c6"
      ],
      "layout": "IPY_MODEL_6a127b571c934a56902123b4ec9aa797"
     }
    },
    "16ef4c9317c44d47bc22d8a483167916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee55bb9f34744079aa2f2512604d8e33",
      "placeholder": "​",
      "style": "IPY_MODEL_e220103f2cc3400d9b2d304ccbe71648",
      "value": "Batches: 100%"
     }
    },
    "5f0a384843f54e52bd44a43b50219f66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a127b571c934a56902123b4ec9aa797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77e49267c4d64a1c8184ce4a93b210c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d7ee6df262b4c4cb10e77cf45dfab2b",
      "placeholder": "​",
      "style": "IPY_MODEL_0ad0c07988804d7f9677179330fe3565",
      "value": " 30/30 [01:17&lt;00:00,  1.05s/it]"
     }
    },
    "7d7ee6df262b4c4cb10e77cf45dfab2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8950c5ac918442d2a3ce191678f0ccd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f0a384843f54e52bd44a43b50219f66",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ceb5bfca7b51499c83a01d00f6cbc1e4",
      "value": 30
     }
    },
    "ceb5bfca7b51499c83a01d00f6cbc1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e220103f2cc3400d9b2d304ccbe71648": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee55bb9f34744079aa2f2512604d8e33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
